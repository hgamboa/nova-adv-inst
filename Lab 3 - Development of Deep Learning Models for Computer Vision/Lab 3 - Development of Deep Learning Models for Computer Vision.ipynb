{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1245a87e-484a-442d-981f-51600ba24eea",
   "metadata": {},
   "source": [
    "<table style=\"background-color:#F5F5F5;\" width=\"100%\">\n",
    "<tr><td style=\"background-color:#F5F5F5;\"><img src=\"logo.png\" width=\"300\" align='right'/></td></tr>     <tr><td>\n",
    "            <h1><center>Aplicações Avançadas de Instrumentação Biomédica (AAIB)</center></h1>\n",
    "            <h3><center>1st Semester - 2025/2026</center></h3>\n",
    "            <h4><center>Universidade Nova de Lisboa - Faculdade de Ciências e Tecnologia</center></h4>\n",
    "</td></tr>\n",
    "    <tr><td><h1><center>Lab 3 - Development of Deep Learning Models for Computer Vision </center></h1></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25602a8-5124-42dc-be5d-e3b2973db281",
   "metadata": {},
   "source": [
    "## Goals:\n",
    "\n",
    "Design, training, and validation of convolutional neural networks (CNNs) models, for image classification tasks using PyTorch.\n",
    "Once the model is trained, an inference program will be developed in Python using Jupyter Notebook to apply the model to new data.\n",
    "\n",
    "Due to the limited computing power of personal computers, the depth of the neural network will be kept minimal to ensure faster training.\n",
    "\n",
    "In the present lab, it will be used a set image flies already labeled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19750c46-c31b-4a02-98b8-cbbbe2608563",
   "metadata": {},
   "source": [
    "## Prerequisites:\n",
    "\n",
    "The following software should be already installed on your computer:\n",
    "* Anaconda Navigator\n",
    "* Jupyter Notebook (part of the default anaconda installation)\n",
    "* Anaconda Prompt (part of the default anaconda installation)\n",
    "* Spyder (part of the default anaconda installation)\n",
    "\n",
    "Install PyTorch:\n",
    "* In https://pytorch.org/ scroll down until you find a table like this:\n",
    "<tr><img src=\"Picture1.png\" width=\"600\" align='center'/></tr>   \n",
    "\n",
    "* Select:\n",
    "  * PyTorch Build: Stable version\n",
    "  * Your OS: choose the one of your computer\n",
    "  * Package: Pip\n",
    "  * Language: Python\n",
    "  * Compute Platform: Choose CPU or CUDA if a NVidea GPU accelerator is available in your computer\n",
    "* Open an Anaconda Prompt, paste the command from the 'Run this Command' section, and press Enter to run it.\n",
    "  * Be patient. The installation can take some time. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f19dd79-4f7e-4adb-85a4-5b3679c32156",
   "metadata": {},
   "source": [
    "## Useful Links\n",
    "* Github of the course: (https://github.com/hgamboa/nova-adv-inst/tree/master/Lab%202)\n",
    "* PyTorch:\n",
    "  * Home page: https://pytorch.org/\n",
    "  * Tutorial: https://docs.pytorch.org/tutorials/\n",
    "  * Video Tutorial: https://www.youtube.com/playlist?list=PL_lsbAsL_o2CTlGHgMxNrKhzP97BaG9ZN\n",
    "  * PyTorch with exemples: https://docs.pytorch.org/tutorials/beginner/pytorch_with_examples.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42460d76-b2ac-48d0-b918-5f93b9892774",
   "metadata": {},
   "source": [
    "# PART 1\n",
    "\n",
    "Create a first notebook to train a neural network on labeled images and use it to classify new data.\n",
    "\n",
    "This part is based on the quickstart PyTorch tutorial.\n",
    "\n",
    "*Advise: Create a folder on your computer to store all the files for this lab.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2a70b1-a656-4bb3-84d6-a810f62dd9d2",
   "metadata": {},
   "source": [
    "## Goal 1.1 - Implement the Quickstart example in Jupyter Notebook:\n",
    "\n",
    "* In your browser go to: https://docs.pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "* From the anaconda navigator start Jupyter Notebook\n",
    "* Start a new Python notebook and remame it\n",
    "* Copy the different parts of the example code into individual cells in your notebook to keep the structure organized and easier to run.\n",
    "* Run eaxh cell and check for errors\n",
    "* Note: Pay close attention to the information provided in the tutorial, as it is essential for understanding the different stages involved in training a PyTorch model.\n",
    "* The last cell if for the model prediction (inference). Confirm that the model is doing mostly the correct classification.\n",
    "\n",
    "### Solutions\n",
    "You can find the following solutions of implmentation\n",
    "* **goal_1_1_FNN_solution.ipynb** - This is the default solution and reflects the example provided in the quickstart tutorial. It uses a Feedforward Neural Network (FNN), which is fast to execute but typically yields lower accuracy.\n",
    "* **goal_1_1_CNN_solution.ipynb** - Replaces the FNN model with a Convolutional Neural Network (CNN), offering improved performance for image-related tasks\n",
    "* **goal_1_1_ResNet_solution** -  Replaces the FNN model with a significantly more complex, pretrained RegNet model, designed for higher accuracy and deeper feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13287150-0ed0-49a5-860f-6ffe2c1dca11",
   "metadata": {},
   "source": [
    "## Goal 1.2 - Data Visiualization and Model Learning Metrics:\n",
    "\n",
    "In Goal 1.1, there is no visualization of the images used to train and to test the model. Add the following functionality to your program to address this.\n",
    "\n",
    "* After the downloading the data sets create a new cell to visualise some of the images. Sugestion: see the example given in: https://docs.pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "* Print the number total of images being used for train and test.\n",
    "* After the classification cell, display the image that was classified. This visualization could help to understand some of the misclassifications.\n",
    "\n",
    "\n",
    "Goal 1.1 there is also  relatively little information about how efficiantly the model is training in terms of loss and accuracy.\n",
    "\n",
    "* To better understand the training process, add a plot showing how the loss changes across iteractions. The expected output should resemble the following:\n",
    "<tr><img src=\"Picture2.png\" width=\"600\" align='center'/></tr>   \n",
    "\n",
    "* Create a second plot that shows how both accuracy and loss change across epochs. The output should resemble the following:\n",
    "<tr><img src=\"Picture3.png\" width=\"600\" align='center'/></tr>   \n",
    "\n",
    "\n",
    "You can find a possible solution to the implementation in: goal_1_2_solution.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935fe682-11bd-4556-87e7-0ca24713fb12",
   "metadata": {},
   "source": [
    "## Goal 1.3 - More on Performance Metrics (optional)\n",
    "\n",
    "When training deep learning (DL) models, it's often necessary to use more evaluation metrics than just accuracy and loss. Modify the Goal 1.1 notebook to:\n",
    "* Display the confusion matrix resulting from applying the model to the test data\n",
    "* Calculate the following metrics:\n",
    "  * Accuracy - The proportion of total predictions that were correct [(TP+TN)/(TP+TN+FP+FN)].\n",
    "  * Precision - The proportion of predicted positives that are actually correct [TP/(TP+FP)].\n",
    "  * Recall - The proportion of actual positives that were correctly identified [TP/(TP+FN)].\n",
    "  * F1 Score - The harmonic mean of precision and recall.\n",
    "\n",
    "You can find a possible solution to the implementation in: goal_1_3_solution.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefa645e-2630-4f89-a834-78fa68e16f5a",
   "metadata": {},
   "source": [
    "# PART 2\n",
    "\n",
    "Considering the course's objective of running inference on edge devices—which often have limited computational power—it's crucial to deploy the application on more performant platforms than Jupyter Notebook. In order to meet this objective, the inference model will be implemented in Python using the Spyder development environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d4d68-7d08-4020-8b95-433acc45cb35",
   "metadata": {},
   "source": [
    "## Goal 2.1 - Implement inference model in Spyder\n",
    "\n",
    "* In spyder open a new program\n",
    "* Use the code already developed in the notebook for the inference (3 last cells)\n",
    "* Download the set of test images from the course GitHub (folder test_images).\n",
    "* Automatize you program to loop over all the imagens and classify them\n",
    "* Display a comparation between the right class (in file name) and the result of the classification\n",
    "  \n",
    "The program you've just built is compatible with devices like the Raspberry Pi. You'll deploy it to one of these machines later in the course.\n",
    "\n",
    "You can find a possible solution to the implementation in: goal_2_1_solution.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df824b52-16a9-4216-a4ea-282877f8ac42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
