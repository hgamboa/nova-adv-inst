{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1245a87e-484a-442d-981f-51600ba24eea",
   "metadata": {},
   "source": [
    "<table style=\"background-color:#F5F5F5;\" width=\"100%\">\n",
    "<tr><td style=\"background-color:#F5F5F5;\"><img src=\"logo.png\" width=\"300\" align='right'/></td></tr>     <tr><td>\n",
    "            <h1><center>Aplicações Avançadas de Instrumentação Biomédica (AAIB)</center></h1>\n",
    "            <h3><center>1st Semester - 2025/2026</center></h3>\n",
    "            <h4><center>Universidade Nova de Lisboa - Faculdade de Ciências e Tecnologia</center></h4>\n",
    "</td></tr>\n",
    "    <tr><td><h1><center>Lab 2 - Development of Machine Learning Models for Signal Classification </center></h1></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25602a8-5124-42dc-be5d-e3b2973db281",
   "metadata": {},
   "source": [
    "## Goals:\n",
    "\n",
    "Training machine learning models using Orange (via Anaconda) to classify signal data such as audio files, ECG recordings, and inertial measurements. Once the model is trained, an inference program will be developed in Python using Jupyter Notebook to apply the model to new data.\n",
    "\n",
    "In the present lab, it will be used a set of audio files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19750c46-c31b-4a02-98b8-cbbbe2608563",
   "metadata": {},
   "source": [
    "## Prerequisites:\n",
    "\n",
    "The following software should be installed on your computer:\n",
    "* Anaconda Navigator\n",
    "* Jupyter Notebook (part of the default anaconda installation)\n",
    "* Anaconda Prompt (part of the default anaconda installation)\n",
    "* Spyder (part of the default anaconda installation)\n",
    "* Orange  (must be installed from anaconda navigator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f19dd79-4f7e-4adb-85a4-5b3679c32156",
   "metadata": {},
   "source": [
    "## Useful Links\n",
    "* Github of the course: (https://github.com/hgamboa/nova-adv-inst/tree/master/Lab%202)\n",
    "* Python library TSFEL for features extraction: (https://tsfel.readthedocs.io/en/latest/descriptions/modules/tsfel.feature_extraction.html)\n",
    "* Pixbay database of music and music effects: (https://pixabay.com/sound-effects/search/talking/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42460d76-b2ac-48d0-b918-5f93b9892774",
   "metadata": {},
   "source": [
    "# PART 1\n",
    "\n",
    "Train a simple machine learning model in Orange using a default dataset and export the model to a file that can be used in a Python program.\n",
    "\n",
    "*Advise: Create a folder on your computer to store all the files for this lab.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2a70b1-a656-4bb3-84d6-a810f62dd9d2",
   "metadata": {},
   "source": [
    "## Goal 1.1 - Train a ML Model:\n",
    "\n",
    "Start the Orange and open a new workflow. Built a flow as shown below:\n",
    "\n",
    "<tr><img src=\"Picture1.png\" width=\"600\" align='center'/></tr>    \n",
    "\n",
    "* In file widget, select the Iris database\n",
    "* Confirm that the data is available with the widget Data Table\n",
    "* Confirm the quality of the model, with the widget’s Test and Score and Confusion Matrix\n",
    "* Save your model, in a folder of your computer, with the widget Save Model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13287150-0ed0-49a5-860f-6ffe2c1dca11",
   "metadata": {},
   "source": [
    "## Goal 1.2 - Run Inference Model in Python Notebook:\n",
    "\n",
    "* From the course guithub (https://github.com/hgamboa/nova-adv-inst/tree/master/Lab%202) download the following file: Test_Iris_Model.ipyth\n",
    "* Start Jupyter Notebook.\n",
    "* Load Test_Iris_Model.ipyth\n",
    "* In cell 2, change the model’s name, to the one given in goal 1.1\n",
    "* Execute all the notebook and analyze the classification result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935fe682-11bd-4556-87e7-0ca24713fb12",
   "metadata": {},
   "source": [
    "## Goal 1.3 - Improving Notebook (optional)\n",
    "\n",
    "Make the necessary modification in the notebook to:\n",
    "* The user be able to choose the 3 features values that will be used\n",
    "* You noticed that the result of the classification is simply a number, correspondent to a class. Modify to print also the name of the class\n",
    "\n",
    "You can find a possible solution to the implementation in: Test_Iris_Model_Solution.ipyth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefa645e-2630-4f89-a834-78fa68e16f5a",
   "metadata": {},
   "source": [
    "# PART 2\n",
    "\n",
    "Create a new machine learning model to classify different music recordings. Follow these steps:\n",
    "* Develop a Python script to load music tracks, extract relevant features, and save them in a CSV file compatible with Orange.\n",
    "* Use Orange to build a classification model for the music files and export the trained model to a file.\n",
    "* Create a Python script to load a new music track and classify it using the previously exported model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6d4d68-7d08-4020-8b95-433acc45cb35",
   "metadata": {},
   "source": [
    "## Goal 2.1 - Installing Extra Libraries:\n",
    "\n",
    "Before proceeding, you'll need to install additional libraries since we're working with sound files. Follow these steps:\n",
    "* Open Anaconda Prompt via Anaconda Navigator.\n",
    "* Install libraries for loading and converting audio tracks to NumPy arrays:\n",
    "  * pip install pydub\n",
    "  * conda install ffmpeg\n",
    "* Install the library for feature extraction:\n",
    "  * pip install tsfel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f07e7e-547c-4828-8956-90b5548c8bd4",
   "metadata": {},
   "source": [
    "## Goal 2.2 - Reading Music File and Extract Features\n",
    "\n",
    "To read the soundtracks and extract its features we are going to use an already developed notebook script.\n",
    "* Download files from the course GitHub ( https://github.com/hgamboa/nova-adv-inst/tree/master/Lab%202)  the following files:\n",
    "  * Sound tracks ….\n",
    "  * extract_audio_features.ipthy\n",
    "* Run the script and confirm that a file, audio_features.csv, was created\n",
    "* Open Features.csv with notepad or excel and analyze its contents.\n",
    "* Take some time to understand the extract_audio_features.ipthy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5b9f5b-b604-4312-bc32-729126da410b",
   "metadata": {},
   "source": [
    "## Goal 2.3 - Building a Python Music Classifier\n",
    "\n",
    "Open the Orange application via Anaconda and build a workflow as illustrated below:\n",
    "\n",
    "<tr><img src=\"Picture2.png\" width=\"700\" align='center'/></tr>   \n",
    "\n",
    "* In widget File:\n",
    "  * Open the audio_features.csv that was created in the previous step\n",
    "  * Rename Feature 1 as Target and change the type to Categorical.\n",
    "\n",
    "<tr><img src=\"Picture3.png\" width=\"600\" align='center'/></tr>  \n",
    "\n",
    "* In the widget Data Table:\n",
    "  * Confirm that the data is properly organized, with one column with the target class and 7 columns with features.\n",
    " \n",
    "<tr><img src=\"Picture4.png\" width=\"600\" align='center'/></tr>  \n",
    "\n",
    "* In the widget rask, select all features\n",
    "  * WARNING: The selected features and their order are defined in this widget. This is important during inference, as the number and order of features must match.  \n",
    "* In the \"Test and Score\" and \"Confusion Matrix\" widgets, check whether the results are valid.\n",
    "* Save de model\n",
    "* Note: Keep in mind that machine learning, like other statistical algorithms, is influenced by random factors. Therefore, you shouldn't expect to get exactly the same results every time you run the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e38856-51c1-45d3-86bc-6acfa2bd57e3",
   "metadata": {},
   "source": [
    "## Goal 2.4 - Run Inference Model in a Python Notebook:\n",
    "\n",
    "Using a similar approach to Part 1, build a music classifier in Python. You may use Jupyter Notebook or Spyder, depending on your preference.\n",
    "\n",
    "* Adapt the program developed in Goal 1.2 to perform the following tasks\n",
    "  * Read the wav file to be classified and convert the audio data into a NumPy array\n",
    "  * Using the TSFEL library, extract the seven features from audio data.\n",
    "  * Load the trained model saved in Goal 2.3\n",
    "  * Classify the loaded music\n",
    "  * Print the classification result\n",
    "* A possible solution can be found in: Test_Audio_Model_Solution.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625b10b0-9373-4624-9cd1-bd03c7a57bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
